{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import pytz\n",
    "\n",
    "import src.data.Dataset as dt\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Umbral de confianza para la detección de objetos\n",
    "threshold_initial = float(0.8)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Configuración de las rutas de los archivos\n",
    "\n",
    "# Ruta de las imagenes a procesar\n",
    "dataset_files = os.path.abspath(\"resources/input/emptyNonEmptyDataset\")\n",
    "\n",
    "# Ruta del fichero CSV con las anotaciones\n",
    "csv_file = os.path.abspath(\"data/processed/10000Train.csv\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Datos para generar las rutas de salida\n",
    "\n",
    "# Ruta de partida para los ficheros de salida\n",
    "output_path = os.path.abspath(\"resources/output_json/\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Fichero del modelo de deteccion\n",
    "detection_model = os.path.abspath(\"models/MegaDetector v4.1, 2020.04.27/md_v4.1.0.pb\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Ruta de repositorios necesarios\n",
    "ai4eutils_path = os.path.abspath(\"data/external/ai4eutils\")\n",
    "CameraTraps_path = os.path.abspath(\"data/external/CameraTraps\")\n",
    "\n",
    "try:\n",
    "    os.environ[\"PYTHONPATH\"]\n",
    "except KeyError:\n",
    "    os.environ[\"PYTHONPATH\"] = \"\"\n",
    "if platform.system() == \"Windows\":\n",
    "    os.environ[\"PYTHONPATH\"] += \";\" + ai4eutils_path\n",
    "    os.environ[\"PYTHONPATH\"] += \";\" + CameraTraps_path\n",
    "else:\n",
    "    os.environ[\"PYTHONPATH\"] += \":\" + ai4eutils_path\n",
    "    os.environ[\"PYTHONPATH\"] += \":\" + CameraTraps_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !python ./data/external/CameraTraps/detection/run_tf_detector_batch.py \"$detection_model\" \"$dataset_files\" \"$file_path\" --recursive --threshold \"$threshold\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Metal device set to: Apple M3\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Is GPU available? tf.test.is_gpu_available: True\n",
      "TensorFlow version: 2.10.0\n",
      "tf.test.is_gpu_available: True\n",
      "12 image files found in the input directory\n",
      "The checkpoint file will be written to /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/output_json/2024-05-23_23-55_0-7/checkpoints\n",
      "TFDetector: Loading graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/data/external/CameraTraps/detection/run_tf_detector.py:73: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "2024-05-23 23:55:03.708353: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-23 23:55:03.708441: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-05-23 23:55:03.710298: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-23 23:55:03.710305: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFDetector: Detection graph loaded.\n",
      "Loaded model in 3.37 seconds\n",
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/c4728IM000143.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 23:55:07.079365: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-23 23:55:07.079386: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]2024-05-23 23:55:07.230791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2024-05-23 23:55:07.327788: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-05-23 23:55:07.356470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-05-23 23:55:08.638633: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1047 } dim { size: -1048 } dim { size: -1049 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" model: \"0\" num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "  8%|▊         | 1/12 [00:09<01:39,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/lince144 (245).JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:13<01:05,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/21_20201025 (6267).JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:17<00:45,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/37_20201024 (472).JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:20<00:34,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/lince125 (283).JPG\n",
      "Writing a new checkpoint after having processed 5 images since last restart\n",
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/MTZ_S1_D07_R1_IMAG0874.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:26<00:21,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/37_20201116 (12451).JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:29<00:17,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/MTZ_S1_C06_R3_IMAG0255.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [00:32<00:13,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/6_20201812 (9693).JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:36<00:09,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/37_20210319 (943).JPG\n",
      "Writing a new checkpoint after having processed 10 images since last restart\n",
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/20_20201024 (409).JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:42<00:03,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/input/prueba/586ae177-23d2-11e8-a6a3-ec086b02610b.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:47<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished inference in 51.82 seconds\n",
      "Output file saved at /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/output_json/2024-05-23_23-55_0-7/2024-05-23_23-55_0-7.json\n",
      "Deleted checkpoint file /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/output_json/2024-05-23_23-55_0-7/checkpoints\n",
      "Done!\n",
      "El archivo /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/data/processed/prueba.csv se ha abierto con éxito.\n",
      "El conjunto de datos se ha guardado correctamente en /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/output_json/2024-05-23_23-55_0-7/2024-05-23_23-55_0-7.csv.\n",
      "\n",
      "CSV file generated: /Users/carlos/Library/Mobile Documents/com~apple~CloudDocs/WORKSPACE/TFG-Cameratraps_Detection/resources/output_json/2024-05-23_23-55_0-7/2024-05-23_23-55_0-7.csv\n",
      "Threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "coverage = False\n",
    "threshold = threshold_initial\n",
    "\n",
    "while not coverage:\n",
    "    threshold_str = str(threshold).replace(\".\", \"-\")\n",
    "\n",
    "    date_time = datetime.now(pytz.timezone(\"Europe/Madrid\")).strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    name = date_time + \"_\" + threshold_str\n",
    "\n",
    "    folder_name = os.path.join(output_path, name)\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    file_path = folder_name + os.sep + name + \".json\"\n",
    "\n",
    "    checkpoint_path = os.path.join(folder_name, \"checkpoints\")\n",
    "\n",
    "    checkpoint_frequency = 5\n",
    "\n",
    "    command = f'python data/external/CameraTraps/detection/run_tf_detector_batch.py \"{detection_model}\" \"{dataset_files}\" \"{file_path}\" --recursive --threshold \"{threshold}\" --checkpoint_path \"{checkpoint_path}\" --checkpoint_frequency \"{checkpoint_frequency}\"'\n",
    "    os.system(command)\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    dataset = dt.load_from_csv(csv_file)\n",
    "    dataset = dt.convert_csv_to_abstract(dataset, dataset_files)\n",
    "\n",
    "    detections_label = []\n",
    "    positives_detected = []\n",
    "    false_positives = []\n",
    "    \n",
    "    for file_name, label in zip(dataset[\"file_name\"].values, dataset[\"label\"].values):\n",
    "        matching_images = [\n",
    "            image for image in data[\"images\"] if image[\"file\"] == file_name\n",
    "        ]\n",
    "\n",
    "        image = matching_images[0]\n",
    "\n",
    "        detections = image[\"detections\"]\n",
    "        detection_label = 0\n",
    "        if len(detections) > 0:\n",
    "            detection_label = 1\n",
    "        detections_label.append(detection_label)\n",
    "\n",
    "        false_positive = 0\n",
    "        if label == 1 and detection_label == 1:\n",
    "            positive_detected = 1\n",
    "        elif label == 1 and detection_label == 0:\n",
    "            positive_detected = 0\n",
    "        elif label == 0:\n",
    "            positive_detected = -1\n",
    "            if detection_label == 1:\n",
    "                false_positive = 1\n",
    "        positives_detected.append(positive_detected)\n",
    "        false_positives.append(false_positive)\n",
    "\n",
    "    dataset[\"detection_label\"] = detections_label\n",
    "    dataset[\"positive_detected\"] = positives_detected\n",
    "    dataset[\"is_false_positive\"] = false_positives\n",
    "\n",
    "    path = folder_name + os.sep + name + \".csv\"\n",
    "    dt.dataset_to_csv(dataset, path)\n",
    "\n",
    "    if 0 in positives_detected:\n",
    "        threshold = float(round((threshold - 0.1),1))\n",
    "    else:\n",
    "        coverage = True\n",
    "\n",
    "print()\n",
    "print(\"CSV file generated: \" + path)\n",
    "print(\"Threshold: \" + str(threshold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
